{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "7hibGRo_54ow",
        "outputId": "ba4334b3-3694-41e8-a11f-63d127afcbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"https://t.co/9z2J3P33Uc FB needs to hurry up and add a laugh/cry button ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±. Since eating my feelings has not fixed the world's problems, I guess I'll try to sleep... HOLY CRAP: DeVos questionnaire appears to include passages from uncited sources https://t.co/FNRoOlfw9s well played. Senator Murray Keep the pressure on: https://t.co/4hfOsmdk0l @datageneral thx Mr Taussig It's interesting how many people contact me about applying for a PhD and don't spell my name right.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "text=\"https://t.co/9z2J3P33Uc FB needs to hurry up and add a laugh/cry button ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±. Since eating my feelings has not fixed the world's problems, I guess I'll try to sleep... HOLY CRAP: DeVos questionnaire appears to include passages from uncited sources https://t.co/FNRoOlfw9s well played. Senator Murray Keep the pressure on: https://t.co/4hfOsmdk0l @datageneral thx Mr Taussig It's interesting how many people contact me about applying for a PhD and don't spell my name right.\"\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD"
      ],
      "metadata": {
        "id": "5MNBLHxtpuDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(text))\n",
        "print(\"tokens: \",len(word_tokenize(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tztv5p856ZSG",
        "outputId": "02086620-1ac8-405b-8805-85a4c159d8ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https', ':', '//t.co/9z2J3P33Uc', 'FB', 'needs', 'to', 'hurry', 'up', 'and', 'add', 'a', 'laugh/cry', 'button', 'ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±', '.', 'Since', 'eating', 'my', 'feelings', 'has', 'not', 'fixed', 'the', 'world', \"'s\", 'problems', ',', 'I', 'guess', 'I', \"'ll\", 'try', 'to', 'sleep', '...', 'HOLY', 'CRAP', ':', 'DeVos', 'questionnaire', 'appears', 'to', 'include', 'passages', 'from', 'uncited', 'sources', 'https', ':', '//t.co/FNRoOlfw9s', 'well', 'played', '.', 'Senator', 'Murray', 'Keep', 'the', 'pressure', 'on', ':', 'https', ':', '//t.co/4hfOsmdk0l', '@', 'datageneral', 'thx', 'Mr', 'Taussig', 'It', \"'s\", 'interesting', 'how', 'many', 'people', 'contact', 'me', 'about', 'applying', 'for', 'a', 'PhD', 'and', 'do', \"n't\", 'spell', 'my', 'name', 'right', '.']\n",
            "tokens:  89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE"
      ],
      "metadata": {
        "id": "bRnMwC5tpsBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnRnDsdB7ExJ",
        "outputId": "bd6b4a63-5f7f-40d0-e01e-1ec6cf42a066"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://t.co/9z2J3P33Uc FB needs to hurry up and add a laugh/cry button ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±.',\n",
              " \"Since eating my feelings has not fixed the world's problems, I guess I'll try to sleep... HOLY CRAP: DeVos questionnaire appears to include passages from uncited sources https://t.co/FNRoOlfw9s well played.\",\n",
              " \"Senator Murray Keep the pressure on: https://t.co/4hfOsmdk0l @datageneral thx Mr Taussig It's interesting how many people contact me about applying for a PhD and don't spell my name right.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PUNCT SENTENCE"
      ],
      "metadata": {
        "id": "in593BV-ppwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer,WordPunctTokenizer\n",
        "print(\"Punctuation based sentence tokenization\\n\")\n",
        "PunktSentenceTokenizer().tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35gPLqnR8tDj",
        "outputId": "8abf3af3-32a3-40f1-a38b-68d556e8a72d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation based sentence tokenization\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://t.co/9z2J3P33Uc FB needs to hurry up and add a laugh/cry button ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±.',\n",
              " \"Since eating my feelings has not fixed the world's problems, I guess I'll try to sleep... HOLY CRAP: DeVos questionnaire appears to include passages from uncited sources https://t.co/FNRoOlfw9s well played.\",\n",
              " \"Senator Murray Keep the pressure on: https://t.co/4hfOsmdk0l @datageneral thx Mr Taussig It's interesting how many people contact me about applying for a PhD and don't spell my name right.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD PUNCT"
      ],
      "metadata": {
        "id": "dkkHEPHipndy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Punctuation based word tokenization\\n\")\n",
        "WordPunctTokenizer().tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_28tQxvK-pjo",
        "outputId": "e55db29c-bf5e-4932-b502-bb6b4fc87152"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation based word tokenization\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https',\n",
              " '://',\n",
              " 't',\n",
              " '.',\n",
              " 'co',\n",
              " '/',\n",
              " '9z2J3P33Uc',\n",
              " 'FB',\n",
              " 'needs',\n",
              " 'to',\n",
              " 'hurry',\n",
              " 'up',\n",
              " 'and',\n",
              " 'add',\n",
              " 'a',\n",
              " 'laugh',\n",
              " '/',\n",
              " 'cry',\n",
              " 'button',\n",
              " 'ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±.',\n",
              " 'Since',\n",
              " 'eating',\n",
              " 'my',\n",
              " 'feelings',\n",
              " 'has',\n",
              " 'not',\n",
              " 'fixed',\n",
              " 'the',\n",
              " 'world',\n",
              " \"'\",\n",
              " 's',\n",
              " 'problems',\n",
              " ',',\n",
              " 'I',\n",
              " 'guess',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'try',\n",
              " 'to',\n",
              " 'sleep',\n",
              " '...',\n",
              " 'HOLY',\n",
              " 'CRAP',\n",
              " ':',\n",
              " 'DeVos',\n",
              " 'questionnaire',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'include',\n",
              " 'passages',\n",
              " 'from',\n",
              " 'uncited',\n",
              " 'sources',\n",
              " 'https',\n",
              " '://',\n",
              " 't',\n",
              " '.',\n",
              " 'co',\n",
              " '/',\n",
              " 'FNRoOlfw9s',\n",
              " 'well',\n",
              " 'played',\n",
              " '.',\n",
              " 'Senator',\n",
              " 'Murray',\n",
              " 'Keep',\n",
              " 'the',\n",
              " 'pressure',\n",
              " 'on',\n",
              " ':',\n",
              " 'https',\n",
              " '://',\n",
              " 't',\n",
              " '.',\n",
              " 'co',\n",
              " '/',\n",
              " '4hfOsmdk0l',\n",
              " '@',\n",
              " 'datageneral',\n",
              " 'thx',\n",
              " 'Mr',\n",
              " 'Taussig',\n",
              " 'It',\n",
              " \"'\",\n",
              " 's',\n",
              " 'interesting',\n",
              " 'how',\n",
              " 'many',\n",
              " 'people',\n",
              " 'contact',\n",
              " 'me',\n",
              " 'about',\n",
              " 'applying',\n",
              " 'for',\n",
              " 'a',\n",
              " 'PhD',\n",
              " 'and',\n",
              " 'don',\n",
              " \"'\",\n",
              " 't',\n",
              " 'spell',\n",
              " 'my',\n",
              " 'name',\n",
              " 'right',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TREEBANK WORD TOKENIZER"
      ],
      "metadata": {
        "id": "37KsNB2G_Nxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "TreebankWordTokenizer().tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDM4ceMu-vPT",
        "outputId": "368d359a-9fbf-4f99-8c44-f108d956c4a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https',\n",
              " ':',\n",
              " '//t.co/9z2J3P33Uc',\n",
              " 'FB',\n",
              " 'needs',\n",
              " 'to',\n",
              " 'hurry',\n",
              " 'up',\n",
              " 'and',\n",
              " 'add',\n",
              " 'a',\n",
              " 'laugh/cry',\n",
              " 'button',\n",
              " 'ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±.',\n",
              " 'Since',\n",
              " 'eating',\n",
              " 'my',\n",
              " 'feelings',\n",
              " 'has',\n",
              " 'not',\n",
              " 'fixed',\n",
              " 'the',\n",
              " 'world',\n",
              " \"'s\",\n",
              " 'problems',\n",
              " ',',\n",
              " 'I',\n",
              " 'guess',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'try',\n",
              " 'to',\n",
              " 'sleep',\n",
              " '...',\n",
              " 'HOLY',\n",
              " 'CRAP',\n",
              " ':',\n",
              " 'DeVos',\n",
              " 'questionnaire',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'include',\n",
              " 'passages',\n",
              " 'from',\n",
              " 'uncited',\n",
              " 'sources',\n",
              " 'https',\n",
              " ':',\n",
              " '//t.co/FNRoOlfw9s',\n",
              " 'well',\n",
              " 'played.',\n",
              " 'Senator',\n",
              " 'Murray',\n",
              " 'Keep',\n",
              " 'the',\n",
              " 'pressure',\n",
              " 'on',\n",
              " ':',\n",
              " 'https',\n",
              " ':',\n",
              " '//t.co/4hfOsmdk0l',\n",
              " '@',\n",
              " 'datageneral',\n",
              " 'thx',\n",
              " 'Mr',\n",
              " 'Taussig',\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'interesting',\n",
              " 'how',\n",
              " 'many',\n",
              " 'people',\n",
              " 'contact',\n",
              " 'me',\n",
              " 'about',\n",
              " 'applying',\n",
              " 'for',\n",
              " 'a',\n",
              " 'PhD',\n",
              " 'and',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'spell',\n",
              " 'my',\n",
              " 'name',\n",
              " 'right',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TWEET TOKENIZER"
      ],
      "metadata": {
        "id": "XMUY3raf_2EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "TweetTokenizer().tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8PJBQYL_jUV",
        "outputId": "86a1a97b-d927-43e0-eee4-21af4d96a1d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://t.co/9z2J3P33Uc',\n",
              " 'FB',\n",
              " 'needs',\n",
              " 'to',\n",
              " 'hurry',\n",
              " 'up',\n",
              " 'and',\n",
              " 'add',\n",
              " 'a',\n",
              " 'laugh',\n",
              " '/',\n",
              " 'cry',\n",
              " 'button',\n",
              " 'ðŸ˜¬',\n",
              " 'ðŸ˜­',\n",
              " 'ðŸ˜“',\n",
              " 'ðŸ¤¢',\n",
              " 'ðŸ™„',\n",
              " 'ðŸ˜±',\n",
              " '.',\n",
              " 'Since',\n",
              " 'eating',\n",
              " 'my',\n",
              " 'feelings',\n",
              " 'has',\n",
              " 'not',\n",
              " 'fixed',\n",
              " 'the',\n",
              " \"world's\",\n",
              " 'problems',\n",
              " ',',\n",
              " 'I',\n",
              " 'guess',\n",
              " \"I'll\",\n",
              " 'try',\n",
              " 'to',\n",
              " 'sleep',\n",
              " '...',\n",
              " 'HOLY',\n",
              " 'CRAP',\n",
              " ':',\n",
              " 'DeVos',\n",
              " 'questionnaire',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'include',\n",
              " 'passages',\n",
              " 'from',\n",
              " 'uncited',\n",
              " 'sources',\n",
              " 'https://t.co/FNRoOlfw9s',\n",
              " 'well',\n",
              " 'played',\n",
              " '.',\n",
              " 'Senator',\n",
              " 'Murray',\n",
              " 'Keep',\n",
              " 'the',\n",
              " 'pressure',\n",
              " 'on',\n",
              " ':',\n",
              " 'https://t.co/4hfOsmdk0l',\n",
              " '@datageneral',\n",
              " 'thx',\n",
              " 'Mr',\n",
              " 'Taussig',\n",
              " \"It's\",\n",
              " 'interesting',\n",
              " 'how',\n",
              " 'many',\n",
              " 'people',\n",
              " 'contact',\n",
              " 'me',\n",
              " 'about',\n",
              " 'applying',\n",
              " 'for',\n",
              " 'a',\n",
              " 'PhD',\n",
              " 'and',\n",
              " \"don't\",\n",
              " 'spell',\n",
              " 'my',\n",
              " 'name',\n",
              " 'right',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MWE TOKENIZER"
      ],
      "metadata": {
        "id": "8Duu2L4fpioa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1=\"I need a little from the chocolate you have. It will be a huge favour\"\n",
        "from nltk.tokenize import MWETokenizer\n",
        "tokenizer=MWETokenizer([('a','little'),('a','huge')])\n",
        "tokenizer.tokenize(text1.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu7WrdLs_8QW",
        "outputId": "6dd02ce1-bf61-4732-cd11-8e99b301ee79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'need',\n",
              " 'a_little',\n",
              " 'from',\n",
              " 'the',\n",
              " 'chocolate',\n",
              " 'you',\n",
              " 'have.',\n",
              " 'It',\n",
              " 'will',\n",
              " 'be',\n",
              " 'a_huge',\n",
              " 'favour']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXTBLOB WORD TOKENIZER"
      ],
      "metadata": {
        "id": "Ua_8s89glJFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "blob=TextBlob(text)\n",
        "blob.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuespicnkROQ",
        "outputId": "ef2731de-6ee2-4897-dc58-71fca77400f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['https', 't.co/9z2J3P33Uc', 'FB', 'needs', 'to', 'hurry', 'up', 'and', 'add', 'a', 'laugh/cry', 'button', 'ðŸ˜¬ðŸ˜­ðŸ˜“ðŸ¤¢ðŸ™„ðŸ˜±', 'Since', 'eating', 'my', 'feelings', 'has', 'not', 'fixed', 'the', 'world', \"'s\", 'problems', 'I', 'guess', 'I', \"'ll\", 'try', 'to', 'sleep', 'HOLY', 'CRAP', 'DeVos', 'questionnaire', 'appears', 'to', 'include', 'passages', 'from', 'uncited', 'sources', 'https', 't.co/FNRoOlfw9s', 'well', 'played', 'Senator', 'Murray', 'Keep', 'the', 'pressure', 'on', 'https', 't.co/4hfOsmdk0l', 'datageneral', 'thx', 'Mr', 'Taussig', 'It', \"'s\", 'interesting', 'how', 'many', 'people', 'contact', 'me', 'about', 'applying', 'for', 'a', 'PhD', 'and', 'do', \"n't\", 'spell', 'my', 'name', 'right'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPACY TOKENIZATION"
      ],
      "metadata": {
        "id": "joXvvdNnl1V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.blank(\"en\")\n",
        "doc=nlp(text)\n",
        "print(\"WORD TOKENS\\n\\n\")\n",
        "[token.text for token in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWVSinPMlMnL",
        "outputId": "286abb59-ee1d-4dac-c8b8-345407a9ae1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORD TOKENS\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://t.co/9z2J3P33Uc',\n",
              " 'FB',\n",
              " 'needs',\n",
              " 'to',\n",
              " 'hurry',\n",
              " 'up',\n",
              " 'and',\n",
              " 'add',\n",
              " 'a',\n",
              " 'laugh',\n",
              " '/',\n",
              " 'cry',\n",
              " 'button',\n",
              " 'ðŸ˜¬',\n",
              " 'ðŸ˜­',\n",
              " 'ðŸ˜“',\n",
              " 'ðŸ¤¢',\n",
              " 'ðŸ™„',\n",
              " 'ðŸ˜±',\n",
              " '.',\n",
              " 'Since',\n",
              " 'eating',\n",
              " 'my',\n",
              " 'feelings',\n",
              " 'has',\n",
              " 'not',\n",
              " 'fixed',\n",
              " 'the',\n",
              " 'world',\n",
              " \"'s\",\n",
              " 'problems',\n",
              " ',',\n",
              " 'I',\n",
              " 'guess',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'try',\n",
              " 'to',\n",
              " 'sleep',\n",
              " '...',\n",
              " 'HOLY',\n",
              " 'CRAP',\n",
              " ':',\n",
              " 'DeVos',\n",
              " 'questionnaire',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'include',\n",
              " 'passages',\n",
              " 'from',\n",
              " 'uncited',\n",
              " 'sources',\n",
              " 'https://t.co/FNRoOlfw9s',\n",
              " 'well',\n",
              " 'played',\n",
              " '.',\n",
              " 'Senator',\n",
              " 'Murray',\n",
              " 'Keep',\n",
              " 'the',\n",
              " 'pressure',\n",
              " 'on',\n",
              " ':',\n",
              " 'https://t.co/4hfOsmdk0l',\n",
              " '@datageneral',\n",
              " 'thx',\n",
              " 'Mr',\n",
              " 'Taussig',\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'interesting',\n",
              " 'how',\n",
              " 'many',\n",
              " 'people',\n",
              " 'contact',\n",
              " 'me',\n",
              " 'about',\n",
              " 'applying',\n",
              " 'for',\n",
              " 'a',\n",
              " 'PhD',\n",
              " 'and',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'spell',\n",
              " 'my',\n",
              " 'name',\n",
              " 'right',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENSIM WORD TOKENIZER"
      ],
      "metadata": {
        "id": "wVqI5PKCntLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import tokenize\n",
        "tokens=list(tokenize(text))\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QmwZNgdnNky",
        "outputId": "f7ce35e8-7783-45f4-dc50-eba34985bcd2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https', 't', 'co', 'z', 'J', 'P', 'Uc', 'FB', 'needs', 'to', 'hurry', 'up', 'and', 'add', 'a', 'laugh', 'cry', 'button', 'Since', 'eating', 'my', 'feelings', 'has', 'not', 'fixed', 'the', 'world', 's', 'problems', 'I', 'guess', 'I', 'll', 'try', 'to', 'sleep', 'HOLY', 'CRAP', 'DeVos', 'questionnaire', 'appears', 'to', 'include', 'passages', 'from', 'uncited', 'sources', 'https', 't', 'co', 'FNRoOlfw', 's', 'well', 'played', 'Senator', 'Murray', 'Keep', 'the', 'pressure', 'on', 'https', 't', 'co', 'hfOsmdk', 'l', 'datageneral', 'thx', 'Mr', 'Taussig', 'It', 's', 'interesting', 'how', 'many', 'people', 'contact', 'me', 'about', 'applying', 'for', 'a', 'PhD', 'and', 'don', 't', 'spell', 'my', 'name', 'right']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KERAS"
      ],
      "metadata": {
        "id": "5YeK5Pxwpfcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=30)\n",
        "tokenizer.fit_on_texts(text)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpTXUPLnvZk",
        "outputId": "a0a4e7a3-0d23-4898-a5ad-e09647965930"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'e': 1,\n",
              " 't': 2,\n",
              " 's': 3,\n",
              " 'o': 4,\n",
              " 'a': 5,\n",
              " 'n': 6,\n",
              " 'r': 7,\n",
              " 'p': 8,\n",
              " 'l': 9,\n",
              " 'i': 10,\n",
              " 'd': 11,\n",
              " 'h': 12,\n",
              " 'u': 13,\n",
              " 'c': 14,\n",
              " 'y': 15,\n",
              " 'g': 16,\n",
              " 'm': 17,\n",
              " 'f': 18,\n",
              " 'b': 19,\n",
              " 'w': 20,\n",
              " \"'\": 21,\n",
              " '3': 22,\n",
              " '9': 23,\n",
              " 'x': 24,\n",
              " 'k': 25,\n",
              " 'z': 26,\n",
              " '2': 27,\n",
              " 'j': 28,\n",
              " 'ðŸ˜¬': 29,\n",
              " 'ðŸ˜­': 30,\n",
              " 'ðŸ˜“': 31,\n",
              " 'ðŸ¤¢': 32,\n",
              " 'ðŸ™„': 33,\n",
              " 'ðŸ˜±': 34,\n",
              " 'v': 35,\n",
              " 'q': 36,\n",
              " '4': 37,\n",
              " '0': 38}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}